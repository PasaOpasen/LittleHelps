"\n"
)
cat(
"Оценка кросс-валидации для не более чем 10 повторений",
boot::cv.glm(
data %>% filter(Count < 11),
glm(
formula = model$call$formula,
data = data %>% filter(Count < 11)
),
K = 10
)$delta[1],
"\n"
)
cat(
"Оценка кросс-валидации для не более чем 6 повторений",
boot::cv.glm(
data %>% filter(Count < 7),
glm(
formula = model$call$formula,
data = data %>% filter(Count < 7)
),
K = 10
)$delta[1],
"\n"
)
}
ResAn = function(res) {
p = ggplot(data %>% mutate(res = res), aes(x = CountGroup, y = res)) +
geom_boxplot() + labs(x = "Группа повторений", y = "Остатки (цель - предсказание)", title =
"Распределения остатков в зависимости от группы повторений") + theme_bw()
print(p)
(p + facet_grid(vars(Action))) %>% print()
(p + facet_grid(vars(BodyType), vars(Action))) %>% print()
return(0)
}
#из этого графика можно сделать вывод, что модель неплохо работает на диапазоне 2-3, но на диапазоне 13-20 ошибка какая-то сильно отличающаяся от тенденции уменьшения ошибок, так что этот диапазон надо бы и вообще убрать, так как там уже играют роль свойства красных волокон, не говорящие о силе
ResAn(data$RM - data$MRM * (1 + 0.0333 * data$Count))
ResVal = function(vals)
ResAn(data$RM - vals)
#ResGraf=function(model)ResVal(predict(model,data))
mysummary = function(mdl) {
cat("-----> ОБЩАЯ ИНФОРМАЦИЯ О МОДЕЛИ:\n")
cat("\n")
gvlma::gvlma(mdl) %>% summary()
cat("\n")
cat("-----> БАЗОВЫЕ ГРАФИКИ:\n")
cat("\n")
par(mfrow = c(2, 2))
plot(mdl)
par(mfrow = c(1, 1))
cat("\n")
cat("-----> ТЕСТ НА НОРМАЛЬНОСТЬ РАСПРЕДЕЛЕНИЯ ОСТАТКОВ\n")
cat("\n")
shapiro.test(mdl$residuals) %>% print()
cat("\n")
qqPlot(mdl, main = "Q-Q plot")
cat("-----> ФАКТОР ИНФЛЯЦИИ ДИСПЕРСИЙ:\n")
cat("\n")
vif(mdl) %>% print()
cat("\n")
cat("-----> ТЕСТ НА АВТОКОРРЕЛЯЦИЮ:\n")
cat("\n")
durbinWatsonTest(mdl) %>% print()
cat("\n")   #тест на автокорреляцию
# cat("-----> ТЕСТ НА ОДНОРОДНОСТЬ ДИСПЕРСИИ:\n");cat("\n")
# ncvTest(mdl)%>% print();cat("\n")    #однородность дисперсии
cat("-----> ТЕСТ НА ВЫБРОСЫ И ВЛИЯТЕЛЬНЫЕ НАБЛЮДЕНИЯ:\n")
cat("\n")
outs = outlierTest(mdl)
outs %>% print()
influ = influencePlot(mdl, main = "Диаграмма влияния", sub = "Размеры кругов пропорциональны расстояниям Кука")
influ %>% print()
cat("-----> ВЫБРОСЫ И ВЛИЯТЕЛЬНЫЕ НАБЛЮДЕНИЯ:\n")
cat("\n")
data[c(outs$p %>% names(), influ %>% rownames()) %>% as.numeric(), ] %>% unique() %>%
select(-Mail) %>% arrange(-RM, -Count) %>% print()
cat("\n")
}
all = function(modelka) {
modelka %>% ShowErrors()
modelka %>% predict(data) %>% ResVal()
modelka %>% mysummary()
}
data %<>% mutate(
Body2 = ifelse(BodyType == "Эндоморф", "Endo", "NonEndo") %>% factor(),
Action2 = ifelse(Action == "Жим", "Up", "Down") %>% factor()
)
data %<>% filter(Count < 11)
b5 = lm(RM ~ I((MRM / Index) ^ 6) + MRM:CountGroup + MRM:Action + MRM:CountGroup:Count - 1,
data)
n14=nls(RM~100*MRM/(a[Action]+b*exp(-c[CountGroup]*Count))+d*(MRM/Index)^6,data,start = list(a=rep(52,3),b=42,c=rep(0.0555,3),d=0))
#4.75
ft = train(
RM ~ I((MRM / Index) ^ 6) + MRM:CountGroup + MRM:Action + MRM:CountGroup:Count - 1,
data = data %>% select(-Mail,-Sex,-Age,-Height,-Weight),
method = "lmStepAIC",
scope = list(upper =  ~ . ^ 3,
lower =  ~ 1),
direction = "both",
metric =  "RMSE",
maximize = FALSE,
trControl = tr
)
library(caret)
tr = trainControl(
method = "repeatedcv",
number = 10,
#p = 0.75,
repeats = 10,
verboseIter = F,
returnResamp = "all",
savePredictions = T,
summaryFunction = defaultSummary
)
d2=data %>% select(MRM,Count,Weight,Height,Index,Action,CountGroup,IndexGroup) %>%
mutate_all(as.numeric) %>%
mutate(pow=MRM*Count,add=(MRM/Index)^6)
d3=d2 %>% mutate(b5=predict(b5,data),n14=predict(n14,data))
trtr=trainControl(
method = "repeatedcv",
number = 10,
#p = 0.75,
repeats = 2,
verboseIter = F,
returnResamp = "final",
savePredictions = T,
summaryFunction = defaultSummary
)
ft1 = train(
y=data$RM,
x = d3,
method = "M5",
metric =  "RMSE",
maximize = FALSE,
trControl = trtr,
tuneLength = 20
)
# 4.90
ft2 = train(
y=data$RM,
x = d3,
method = "ridge",
metric =  "RMSE",
maximize = FALSE,
trControl = trtr
)
#4.75
ft = train(
RM ~ I((MRM / Index) ^ 6) + MRM:CountGroup + MRM:Action + MRM:CountGroup:Count - 1,
data = data %>% select(-Mail,-Sex,-Age,-Height,-Weight),
method = "lmStepAIC",
scope = list(upper =  ~ . ^ 3,
lower =  ~ 1),
direction = "both",
metric =  "RMSE",
maximize = FALSE,
trControl = trtr
)
results <- resamples(list('LVQ'=ft1, 'GBM'=ft2, 'SVM'=ft))
# boxplots of results
bwplot(results)
# dot plots of results
dotplot(results)
modelLookup("M5")
ft1 = train(
y=data$RM,
x = d3,
method = "M5",
metric =  "RMSE",
maximize = FALSE,
trControl = trtr,
tuneLength = 50
)
results <- resamples(list('LVQ'=ft1, 'GBM'=ft2, 'SVM'=ft))
# boxplots of results
bwplot(results)
# 4.90
ft2 = train(
y=data$RM,
x = d3,
method = "ridge",
metric =  "RMSE",
maximize = FALSE,
trControl = trtr
)
results <- resamples(list('LVQ'=ft1, 'GBM'=ft2, 'SVM'=ft))
# boxplots of results
bwplot(results)
shiny::runApp('RMbyMRMestimating')
runApp()
runApp('RMbyMRMestimating')
runApp('RMbyMRMestimating')
runApp('RMbyMRMestimating')
seq(100,50,by=5)
seq(100,50,by=-5)
runApp('RMbyMRMestimating')
runApp('RMbyMRMestimating')
runApp('RMbyMRMestimating')
runApp('RMbyMRMestimating')
runApp('RMbyMRMestimating')
runApp('RMbyMRMestimating')
runApp('RMbyMRMestimating')
#Загрузка данных####
library(tidyverse)
library(magrittr)
library(ggformula)
library(ggthemes)
library(tidyquant)
library(ggvis)
library(plotrix)
library(car)
#library(DAAG)
library(leaps)
library(plotly)
data = read_tsv(
"data(rus).tsv",
skip = 1,
col_names = F,
na = "",
col_types = "fddnfffnnnff",
comment = "#"
) %>% tbl_df()
colnames(data) = c(
"Date",
"RM",
"MRM",
"Count",
"Action",
"Sex",
"Experience",
"Age",
"Weight",
"Height",
"BodyType",
"Mail"
)
data %<>% #filter(Count<=20) %>%
arrange(MRM, Count, Weight) %>%  mutate(
CountGroup = cut(Count, breaks = c(1, 3, 6, 10, 20, 40)),
AgeGroup = cut(Age, breaks = c(1, 19, 27, 35, 70)),
Experience = factor(
Experience,
levels = c(
"До двух лет",
"2-3 года",
"4-5 лет",
"6-10 лет",
"11-15 лет" ,
"больше 15 лет"
),
ordered = T
),
Index = Weight / (0.01 * Height) ^ 2,
IndexGroup = cut(Index, breaks = c(0, 16, 18.5, 24.99, 30, 35, 40, 60))
) %>% select(-Date)#,-Mail) %>% filter(Count>1,MRM<RM)
levels(data$CountGroup) = c("2-3", "4-6", "7-10", "11-20", ">20")
levels(data$AgeGroup) = c("<20", "20-27", "28-35", ">35")
levels(data$IndexGroup) = c(
"выраженный дефицит",
"дефицит",
"норма",
"избыток",
"ожирение1",
"ожирение2",
"ожирение3"
)
ex = data$Experience %>% as.numeric()
ex[ex == 6] = 5
ex %<>% factor()
levels(ex) = c("До двух лет", "2-3 года", "4-5 лет", "6-10 лет", "больше 10 лет")
data %<>% mutate(Experience = factor(ex, ordered = T))
allrows = 1:nrow(data)
maxerror = 5
#уникальные записи (где один от каждого человека берётся только одна запись)
#объяснить, по каким признакам людей считать одинаковыми
data.unique = data %>% select(AgeGroup, Height, BodyType, Experience, Sex, IndexGroup) %>% unique()
#функции
getparam = function(vec) {
ln = length(levels(vec))
x = numeric(ln)
ns = character(ln)
for (i in seq(ln)) {
x[i] = sum(vec == levels(vec)[i]) / length(vec)
ns[i] = paste0(levels(vec)[i], " (", round(x[i] * 100, 2), "%)")
}
return(list(x = x, ns = ns))
}
getPIE = function(vec, main = "") {
lst = getparam(vec)
pie(x = lst$x,
labels = lst$ns,
main = main)
}
getFan = function(vec, main = "") {
pr = getparam(vec)
fan.plot(pr$x, labels = pr$ns, main = main)
}
data.backup = data
data %<>% filter(Count <= 20)
data %>% summary()
Error = function(target, weight)
(target - weight) ^ 2 %>% mean() %>% sqrt()
Show = function(vals, df = data) {
#vals=predict(model,df)
err = df$RM - vals
cbind(
Fact = round(vals),
Target = df$RM,
Set = paste0(df$MRM, "*", df$Count),
ERROR = abs(df$RM - vals),
ErrorPercent = abs(err) / df$RM * 100,
df[, c(3:15)]
) %>% tbl_df() %>% select(-Count, -Mail, -Experience, IndexGroup) %>% arrange(-ERROR, -ErrorPercent, Weight) %>%
filter(ERROR > 1) %>% View()
cat("\n")
rg = range(err)#;print(err);print(rg)
if (rg[1] < 0)
cat("------------> Наибольшая ошибка в большую сторону:",
-rg[1],
"\n")
if (rg[2] > 0)
cat("------------> Наибольшая ошибка в меньшую сторону:", rg[2], "\n")
s = sum(abs(err) / df$RM * 100 > maxerror)
len = length(err)
cat(
"Модель ошиблась более чем на",
maxerror,
"% в",
s,
"случаях из",
len,
"(",
s / len * 100,
"%)\n"
)
s = sum(abs(err) > maxerror)
cat(
"Модель ошиблась более чем на",
maxerror,
"кг в",
s,
"случаях из",
len,
"(",
s / len * 100,
"%)\n"
)
cat("----------------> Статистика по ошибкам в процентах:\n")
(abs(df$RM - vals) / df$RM * 100) %>% summary() %>% print()
cat("-------------------> Среднеквадратичная ошибка:",
Error(vals, df$RM),
"\n")
}
ShowErrors = function(model,
power.coef = 1,
sum.coef = 0) {
Show(predict(model, data) * power.coef + sum.coef)
cat(
"Оценка кросс-валидации для всего набора данных",
boot::cv.glm(data, glm(
formula = model$call$formula, data = data
), K = 10)$delta[1],
"\n"
)
cat(
"Оценка кросс-валидации для не более чем 10 повторений",
boot::cv.glm(
data %>% filter(Count < 11),
glm(
formula = model$call$formula,
data = data %>% filter(Count < 11)
),
K = 10
)$delta[1],
"\n"
)
cat(
"Оценка кросс-валидации для не более чем 6 повторений",
boot::cv.glm(
data %>% filter(Count < 7),
glm(
formula = model$call$formula,
data = data %>% filter(Count < 7)
),
K = 10
)$delta[1],
"\n"
)
}
ResAn = function(res) {
p = ggplot(data %>% mutate(res = res), aes(x = CountGroup, y = res)) +
geom_boxplot() + labs(x = "Группа повторений", y = "Остатки (цель - предсказание)", title =
"Распределения остатков в зависимости от группы повторений") + theme_bw()
print(p)
(p + facet_grid(vars(Action))) %>% print()
(p + facet_grid(vars(BodyType), vars(Action))) %>% print()
return(0)
}
#из этого графика можно сделать вывод, что модель неплохо работает на диапазоне 2-3, но на диапазоне 13-20 ошибка какая-то сильно отличающаяся от тенденции уменьшения ошибок, так что этот диапазон надо бы и вообще убрать, так как там уже играют роль свойства красных волокон, не говорящие о силе
ResAn(data$RM - data$MRM * (1 + 0.0333 * data$Count))
ResVal = function(vals)
ResAn(data$RM - vals)
#ResGraf=function(model)ResVal(predict(model,data))
mysummary = function(mdl) {
cat("-----> ОБЩАЯ ИНФОРМАЦИЯ О МОДЕЛИ:\n")
cat("\n")
gvlma::gvlma(mdl) %>% summary()
cat("\n")
cat("-----> БАЗОВЫЕ ГРАФИКИ:\n")
cat("\n")
par(mfrow = c(2, 2))
plot(mdl)
par(mfrow = c(1, 1))
cat("\n")
cat("-----> ТЕСТ НА НОРМАЛЬНОСТЬ РАСПРЕДЕЛЕНИЯ ОСТАТКОВ\n")
cat("\n")
shapiro.test(mdl$residuals) %>% print()
cat("\n")
qqPlot(mdl, main = "Q-Q plot")
cat("-----> ФАКТОР ИНФЛЯЦИИ ДИСПЕРСИЙ:\n")
cat("\n")
vif(mdl) %>% print()
cat("\n")
cat("-----> ТЕСТ НА АВТОКОРРЕЛЯЦИЮ:\n")
cat("\n")
durbinWatsonTest(mdl) %>% print()
cat("\n")   #тест на автокорреляцию
# cat("-----> ТЕСТ НА ОДНОРОДНОСТЬ ДИСПЕРСИИ:\n");cat("\n")
# ncvTest(mdl)%>% print();cat("\n")    #однородность дисперсии
cat("-----> ТЕСТ НА ВЫБРОСЫ И ВЛИЯТЕЛЬНЫЕ НАБЛЮДЕНИЯ:\n")
cat("\n")
outs = outlierTest(mdl)
outs %>% print()
influ = influencePlot(mdl, main = "Диаграмма влияния", sub = "Размеры кругов пропорциональны расстояниям Кука")
influ %>% print()
cat("-----> ВЫБРОСЫ И ВЛИЯТЕЛЬНЫЕ НАБЛЮДЕНИЯ:\n")
cat("\n")
data[c(outs$p %>% names(), influ %>% rownames()) %>% as.numeric(), ] %>% unique() %>%
select(-Mail) %>% arrange(-RM, -Count) %>% print()
cat("\n")
}
all = function(modelka) {
modelka %>% ShowErrors()
modelka %>% predict(data) %>% ResVal()
modelka %>% mysummary()
}
data %<>% mutate(
Body2 = ifelse(BodyType == "Эндоморф", "Endo", "NonEndo") %>% factor(),
Action2 = ifelse(Action == "Жим", "Up", "Down") %>% factor()
)
data %<>% filter(Count < 11)
b5 = lm(RM ~ I((MRM / Index) ^ 6) + MRM:CountGroup + MRM:Action + MRM:CountGroup:Count - 1,
data)
n14=nls(RM~100*MRM/(a[Action]+b*exp(-c[CountGroup]*Count))+d*(MRM/Index)^6,data,start = list(a=rep(52,3),b=42,c=rep(0.0555,3),d=0))
mrm3 = function(RM,
count,
Action = 'Присед',
Weight = 70,
Height = 170) {
ctg = 3
if (count < 7) {
ctg = 2
}
if (count < 4) {
ctg = 1
}
act = 0
if (Action == "Тяга") {
act = cf[5]
} else if (Action == "Присед") {
act = cf[6]
}
polyroot(c(-RM, cf[1 + ctg] + count * cf[6 + ctg] + act, 0, 0, 0, 0, cf[1] *
((0.01 * Height) ^ 2 / Weight) ^ 6))[1] %>% Re()
}
action.levels=levels(data$Action)
count.levels=levels(data$CountGroup)
f=function(MRM,Count,Action='Жим',Weight=70,Height=170){
if(Count<2){
Count=2
} else if(Count>10){
Count=10
}
act=factor(Action,levels =globalenv()$action.levels)
up=c(4,8,11)
lv=globalenv()$count.levels
cg=lv[Count<up] %>% first() %>% factor(levels=lv)
#print(environment()$action.levels)
#print(MRM)
#print(Count)
#print(act)
#print(cg)
#print(Weight/(0.01*Height)^2)
df=data.frame(MRM=MRM,
Count=Count,
Action=act,
CountGroup=cg,
Index=Weight/(0.01*Height)^2)
#df %>% print()
predict(globalenv()$b5,
df,
se.fit = T,
interval = "confidence",
level=0.999)[[1]] %>% return()
}
cf=coefficients(b5)
save(f, count.levels, action.levels, cf, mrm3, b5, file = "./RMbyMRMestimating/entire_data.rdata")
save(f, count.levels, action.levels, cf, mrm3, b5, n14,file = "./RMbyMRMestimating/entire_data.rdata")
predict(n14,data[1,])
shiny::runApp('RMbyMRMestimating')
runApp('RMbyMRMestimating')
